Geoffrey Everest Hinton (born 6 December 1947) is a British-Canadian computer scientist, cognitive scientist, cognitive psychologist, known for his work on artificial neural networks which earned him the title as the "Godfather of AI".

Hinton is University Professor Emeritus at the University of Toronto. From 2013 to 2023, he divided his time working for Google (Google Brain) and the University of Toronto, before publicly announcing his departure from Google in May 2023, citing concerns about the many risks of artificial intelligence (AI) technology.[9][10] In 2017, he co-founded and became the chief scientific advisor of the Vector Institute in Toronto.[11][12]

With David Rumelhart and Ronald J. Williams, Hinton was co-author of a highly cited paper published in 1986 that popularised the backpropagation algorithm for training multi-layer neural networks,[13] although they were not the first to propose the approach.[14] Hinton is viewed as a leading figure in the deep learning community.[20] The image-recognition milestone of the AlexNet designed in collaboration with his students Alex Krizhevsky[21] and Ilya Sutskever for the ImageNet challenge 2012[22] was a breakthrough in the field of computer vision.[23]

Hinton received the 2018 Turing Award, often referred to as the "Nobel Prize of Computing", together with Yoshua Bengio and Yann LeCun, for their work on deep learning.[24] They are sometimes referred to as the "Godfathers of Deep Learning",[25][26] and have continued to give public talks together.[27][28] He was also awarded the 2024 Nobel Prize in Physics, shared with John Hopfield.[29][30]

In May 2023, Hinton announced his resignation from Google to be able to "freely speak out about the risks of A.I."[31] He has voiced concerns about deliberate misuse by malicious actors, technological unemployment, and existential risk from artificial general intelligence.[32] He noted that establishing safety guidelines will require cooperation among those competing in use of AI in order to avoid the worst outcomes.[33] After receiving the Nobel Prize, he called for urgent research into AI safety to figure out how to control AI systems smarter than humans.[34][35]

Education
Hinton was educated at Clifton College in Bristol[36] and the University of Cambridge as an undergraduate student of King's College, Cambridge. After repeatedly changing his degree between different subjects like natural sciences, history of art, and philosophy, he eventually graduated with a BA degree in experimental psychology in 1970.[8] He continued his study at the University of Edinburgh where he was awarded a PhD in artificial intelligence in 1978 for research supervised by Christopher Longuet-Higgins.[37][38]

Career and research
After his PhD, Hinton worked at the University of Sussex and at the MRC Applied Psychology Unit, and after difficulty finding funding in Britain,[39] the University of California, San Diego and Carnegie Mellon University.[8] He was the founding director of the Gatsby Charitable Foundation Computational Neuroscience Unit at University College London.[8] He is currently[40] University Professor Emeritus in the computer science department at the University of Toronto, where he has been affiliated since 1987.[41]

Upon arrival in Canada, Geoffrey Hinton was appointed at the Canadian Institute for Advanced Research (CIFAR) in 1987 as a Fellow in CIFAR's first research program, Artificial Intelligence, Robotics & Society.[42] In 2004, Hinton and collaborators successfully proposed the launch of a new program at CIFAR, Neural Computation and Adaptive Perception[43] (or NCAP, which today is named Learning in Machines & Brains). Hinton would go on to lead NCAP for ten years.[44] Among the members of the program are Yoshua Bengio and Yann LeCun, with whom Hinton would go on to win the ACM A.M. Turing Award in 2018.[45] All three Turing winners continue to be members of the CIFAR Learning in Machines and Brains program.[46]

Hinton taught a free online course on Neural Networks on the education platform Coursera in 2012.[47] He joined Google in March 2013 when his company, DNNresearch Inc., was acquired, and was at that time planning to "divide his time between his university research and his work at Google".[48]

Hinton's research concerns ways of using neural networks for machine learning, memory, perception, and symbol processing. He has written or co-written more than 200 peer reviewed publications.[1][49]

While Hinton was a postdoc at UC San Diego, David E. Rumelhart and Hinton and Ronald J. Williams applied the backpropagation algorithm to multi-layer neural networks. Their experiments showed that such networks can learn useful internal representations of data.[13] In a 2018 interview,[50] Hinton said that "David E. Rumelhart came up with the basic idea of backpropagation, so it's his invention". Although this work was important in popularising backpropagation, it was not the first to suggest the approach.[14] Reverse-mode automatic differentiation, of which backpropagation is a special case, was proposed by Seppo Linnainmaa in 1970, and Paul Werbos proposed to use it to train neural networks in 1974.[14]

In 1985, Hinton co-invented Boltzmann machines with David Ackley and Terry Sejnowski.[51] His other contributions to neural network research include distributed representations, time delay neural network, mixtures of experts, Helmholtz machines and product of experts.[52] An accessible introduction to Geoffrey Hinton's research can be found in his articles in Scientific American in September 1992 and October 1993.[53] In 2007, Hinton coauthored an unsupervised learning paper titled Unsupervised learning of image transformations.[54] In 2008, he developed the visualization method t-SNE with Laurens van der Maaten.[55][56]

In October and November 2017 respectively, Hinton published two open access research papers on the theme of capsule neural networks,[57][58] which according to Hinton, are "finally something that works well".[59]

At the 2022 Conference on Neural Information Processing Systems (NeurIPS) he introduced a new learning algorithm for neural networks that he calls the "Forward-Forward" algorithm. The idea of the new algorithm is to replace the traditional forward-backward passes of backpropagation with two forward passes, one with positive (i.e. real) data and the other with negative data that could be generated solely by the network.[60][61]

In May 2023, Hinton publicly announced his resignation from Google. He explained his decision by saying that he wanted to "freely speak out about the risks of A.I." and added that a part of him now regrets his life's work.[9][31]

Notable former PhD students and postdoctoral researchers from his group include Peter Dayan,[62] Sam Roweis,[62] Max Welling,[62] Richard Zemel,[37][2] Brendan Frey,[3] Radford M. Neal,[4] Yee Whye Teh,[5] Ruslan Salakhutdinov,[6] Ilya Sutskever,[7] Yann LeCun,[63] Alex Graves,[62] Zoubin Ghahramani,[62] and Peter Fitzhugh Brown.[64]

Honours and awards

In 2016, from left to right,
Russ Salakhutdinov, Richard S. Sutton, Geoffrey Hinton, Yoshua Bengio, and Steve Jurvetson
Hinton was elected a Fellow of the Royal Society (FRS) in 1998.[65] He was the first winner of the Rumelhart Prize in 2001.[66] His certificate of election for the Royal Society reads:

Geoffrey E. Hinton is internationally known for his work on artificial neural nets, especially how they can be designed to learn without the aid of a human teacher. He has compared effects of brain damage with effects of losses in such a net, and found striking similarities with human impairment, such as for recognition of names and losses of categorisation. His work includes studies of mental imagery, and inventing puzzles for testing originality and creative intelligence. It is conceptual, mathematically sophisticated, and experimental. He brings these skills together with striking effect to produce important work of great interest.[67]
In 2001, Hinton was awarded an honorary doctorate from the University of Edinburgh.[68] He was the 2005 recipient of the IJCAI Award for Research Excellence lifetime-achievement award.[69] He was awarded the 2011 Herzberg Canada Gold Medal for Science and Engineering.[70] In 2012, he received the Canada Council Killam Prize in Engineering. In 2013, Hinton was awarded an honorary doctorate from the Universit√© de Sherbrooke.[71]

In 2016, he was elected a foreign member of National Academy of Engineering "for contributions to the theory and practice of artificial neural networks and their application to speech recognition and computer vision".[72] He received the 2016 IEEE/RSE Wolfson James Clerk Maxwell Award.[73]

He won the BBVA Foundation Frontiers of Knowledge Award (2016) in the Information and Communication Technologies category, "for his pioneering and highly influential work" to endow machines with the ability to learn.[74]

Together with Yann LeCun, and Yoshua Bengio, Hinton won the 2018 Turing Award for conceptual and engineering breakthroughs that have made deep neural networks a critical component of computing.[75][76][77]

In 2018, he became a Companion of the Order of Canada.[78] In 2021, he received the Dickson Prize in Science from the Carnegie Mellon University[79] and in 2022 the Princess of Asturias Award in the Scientific Research category, along with Yann LeCun, Yoshua Bengio, and Demis Hassabis.[80] In 2023, he was named an ACM Fellow.[81] In 2023, he was named a Highly Ranked Scholar by ScholarGPS for both lifetime and prior five years. [82]

In 2024, he was jointly awarded the Nobel Prize in Physics with John Hopfield "for foundational discoveries and inventions that enable machine learning with artificial neural networks." His development of the Boltzmann machine was explicitly mentioned in the citation.[29][83] When the New York Times reporter Cade Metz asked Hinton to explain in simpler terms how the Boltzmann machine could "pretrain" backpropagation networks, Hinton quipped that Richard Feynman reportedly said: "Listen, buddy, if I could explain it in a couple of minutes, it wouldn't be worth the Nobel Prize."[84]

Views
Risks of artificial intelligence
See also: AI safety
External videos
video icon Geoffrey Hinton shares his thoughts on AI's benefits and dangers, 60 Minutes YouTube video
In 2023, Hinton expressed concerns about the rapid progress of AI.[32][31] Hinton previously believed that artificial general intelligence (AGI) was "30 to 50 years or even longer away."[31] However, in a March 2023 interview with CBS, he stated that "general-purpose AI" may be fewer than 20 years away and could bring about changes "comparable in scale with the industrial revolution or electricity."[32]

In an interview with The New York Times published on 1 May 2023,[31] Hinton announced his resignation from Google so he could "talk about the dangers of AI without considering how this impacts Google."[85] He noted that "a part of him now regrets his life's work".[31][10]

In early May 2023, Hinton claimed in an interview with BBC that AI might soon surpass the information capacity of the human brain. He described some of the risks posed by these chatbots as "quite scary". Hinton explained that chatbots have the ability to learn independently and share knowledge. This means that whenever one copy acquires new information, it is automatically disseminated to the entire group. This allows AI chatbots to have the capability to accumulate knowledge far beyond the capacity of any individual.[86]

Existential risk from AGI
Hinton has expressed concerns about the possibility of an AI takeover, stating that "it's not inconceivable" that AI could "wipe out humanity".[32] Hinton states that AI systems capable of intelligent agency will be useful for military or economic purposes.[87] He worries that generally intelligent AI systems could "create sub-goals" that are unaligned with their programmers' interests.[88] He states that AI systems may become power-seeking or prevent themselves from being shut off, not because programmers intended them to, but because those sub-goals are useful for achieving later goals.[86] In particular, Hinton says "we have to think hard about how to control" AI systems capable of self-improvement.[89]

Catastrophic misuse
Hinton reports concerns about deliberate misuse of AI by malicious actors, stating that "it is hard to see how you can prevent the bad actors from using [AI] for bad things."[31] In 2017, Hinton called for an international ban on lethal autonomous weapons.[90]

Economic impacts
Hinton was previously optimistic about the economic effects of AI, noting in 2018 that: "The phrase 'artificial general intelligence' carries with it the implication that this sort of single robot is suddenly going to be smarter than you. I don't think it's going to be that. I think more and more of the routine things we do are going to be replaced by AI systems."[91] Hinton also previously argued that AGI won't make humans redundant: "[AI in the future is] going to know a lot about what you're probably going to want to do... But it's not going to replace you."[91]

In 2023, however, Hinton became "worried that AI technologies will in time upend the job market" and take away more than just "drudge work."[31] He again stated in 2024 that the British government will have to establish a universal basic income to deal with the impact of AI on inequality.[92] In Hinton's view, AI will boost productivity and generate more wealth. But unless the government intervenes, it will only make the rich richer and hurt the people who might lose their jobs. "That's going to be very bad for society," he said.[93]

Politics
Hinton moved from the U.S. to Canada in part due to disillusionment with Ronald Reagan-era politics and disapproval of military funding of artificial intelligence.[39]

In August 2024, Hinton co-authored a letter with Yoshua Bengio, Stuart Russell, and Lawrence Lessig in support of SB 1047, a California AI safety bill that would require companies training models which cost more than $100 million to perform risk assessments before deployment. They claimed the legislation was the "bare minimum for effective regulation of this technology."[94][95]

Personal life
Hinton's second wife, Rosalind Zalin, died of ovarian cancer in 1994; his third wife, Jacqueline "Jackie" Ford, died of pancreatic cancer in 2018.[96][97]

Hinton is the great-great-grandson of the mathematician and educator Mary Everest Boole and her husband, the logician George Boole.[98] George Boole's work eventually became one of the foundations of modern computer science. Another great-great-grandfather of his was the surgeon and author James Hinton,[99] who was the father of the mathematician Charles Howard Hinton.

Hinton's father was the entomologist Howard Hinton.[8][100] His middle name comes from another relative, George Everest, the Surveyor General of India after whom the mountain is named.[39] He is the nephew of the economist Colin Clark